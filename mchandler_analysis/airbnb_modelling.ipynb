{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading, Re-Pre-Processing and Feature Engineering\n",
    "\n",
    "Our first step in the EDA process is to load the `AB_NYC_2019.csv` dataset. Missing values handled, log_price created, host_type_category potentially created based on findings in the EDA process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded and initial cleaning/preparation assumed complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"..\\\\data\\\\AB_NYC_2019.csv\")\n",
    "    df['reviews_per_month'] = df['reviews_per_month'].fillna(0)\n",
    "    df['name'] = df['name'].fillna('Unknown')\n",
    "    df['host_name'] = df['host_name'].fillna('Unknown')\n",
    "    if 'price' in df.columns and df['price'].min() >= 0:\n",
    "        df['log_price'] = np.log1p(df['price'])\n",
    "    bins_host = [0, 1, 2, 5, 10, 50, df['calculated_host_listings_count'].max() + 1]\n",
    "    labels_host = ['1', '2', '3-5', '6-10', '11-50', '51+']\n",
    "    df['host_type_category'] = pd.cut(df['calculated_host_listings_count'], bins=bins_host, labels=labels_host, right=True)\n",
    "    print(\"DataFrame loaded and initial cleaning/preparation assumed complete.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Ensure df is loaded and preprocessed in notebook.\")\n",
    "    df = pd.DataFrame({\n",
    "        'price': np.random.exponential(150, 5000),\n",
    "        'log_price': np.log1p(np.random.exponential(150, 5000)),\n",
    "        'room_type': np.random.choice(['Entire home/apt', 'Private room', 'Shared room'], 5000, p=[0.5, 0.45, 0.05]),\n",
    "        'minimum_nights': np.random.choice([1,2,3,7,30,90], 5000, p=[0.5,0.2,0.1,0.1,0.05,0.05]),\n",
    "        'calculated_host_listings_count': np.random.choice([1,2,3,10,50,100], 5000, p=[0.6,0.15,0.1,0.05,0.05,0.05]),\n",
    "        'number_of_reviews': np.random.randint(0,100,5000),\n",
    "        'availability_365': np.random.randint(0, 366, 5000),\n",
    "        'reviews_per_month': np.random.rand(5000) * 5,\n",
    "        'neighbourhood_group': np.random.choice(['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'], 5000),\n",
    "        'neighbourhood': [f\"Hood_{i%20}_{np.random.choice(['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'])}\" for i in range(5000)],\n",
    "        'id': range(5000)\n",
    "    })\n",
    "    bins_host = [0, 1, 2, 5, 10, 50, df['calculated_host_listings_count'].max() + 1]\n",
    "    labels_host = ['1', '2', '3-5', '6-10', '11-50', '51+']\n",
    "    df['host_type_category'] = pd.cut(df['calculated_host_listings_count'], bins=bins_host, labels=labels_host, right=True)\n",
    "    print(\"Using dummy data for script execution.\")\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Price Tiers (for Neighborhood Profiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Defining Price Tiers ---\n",
      "Percentiles used for tiers: Q1=$69.00, Q3=$175.00, Q95=$355.00, Max=$10000.00\n",
      "\n",
      "Value counts for 'price_tier' (%):\n",
      "price_tier\n",
      "Budget           25.301156\n",
      "Mid-Range        49.794458\n",
      "Premium          19.912056\n",
      "Upper Premium     4.992331\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Price Tier Definitions Used:\n",
      "  Budget: $0.00 to $69.00\n",
      "  Mid-Range: $69.00 to $175.00\n",
      "  Premium: $175.00 to $355.00\n",
      "  Upper Premium: $355.00 to $10000.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Defining Price Tiers ---\")\n",
    "\n",
    "if 'price' in df.columns:\n",
    "    # Calculate the required percentiles\n",
    "    price_q1 = df['price'].quantile(0.25)    # 25th percentile\n",
    "    price_q3 = df['price'].quantile(0.75)    # 75th percentile\n",
    "    price_q95 = df['price'].quantile(0.95)   # 95th percentile\n",
    "    max_price = df['price'].max()\n",
    "\n",
    "    print(f\"Percentiles used for tiers: Q1=${price_q1:.2f}, Q3=${price_q3:.2f}, Q95=${price_q95:.2f}, Max=${max_price:.2f}\")\n",
    "\n",
    "    # Define bins and labels for 4 tiers\n",
    "    price_bins = [-0.01, price_q1, price_q3, price_q95, max_price + 1]\n",
    "    price_labels = ['Budget', 'Mid-Range', 'Premium', 'Upper Premium']\n",
    "    \n",
    "    # Check for non-monotonic bins which can happen if quantiles are equal\n",
    "    # (e.g., if Q3 and Q95 are the same due to data distribution)\n",
    "    is_monotonic = all(price_bins[i] < price_bins[i+1] for i in range(len(price_bins)-2)) # Check up to Q95\n",
    "    if price_bins[len(price_bins)-2] > price_bins[len(price_bins)-1]: # Check last bin edge with max_price + 1\n",
    "        is_monotonic = False # max_price + 1 should always be greater unless max_price itself is problematic\n",
    "\n",
    "    if not is_monotonic or len(set(price_bins)) < len(price_bins):\n",
    "        print(\"\\nWarning: Bin edges are not strictly monotonic or contain duplicates.\")\n",
    "        print(f\"Original calculated bins: {[-0.01, price_q1, price_q3, price_q95, max_price + 1]}\")\n",
    "        # Attempt to create unique sorted bins. This might reduce the number of bins if quantiles are equal.\n",
    "        price_bins = sorted(list(set([-0.01, price_q1, price_q3, price_q95, max_price + 1])))\n",
    "        print(f\"Adjusted unique sorted bins: {price_bins}\")\n",
    "        \n",
    "        # If after adjustment we don't have enough bins for 4 labels, we might need to simplify\n",
    "        if len(price_bins) < 5: # Need 5 edges for 4 labels\n",
    "            print(\"Could not form 4 distinct tiers with current quantiles. Consider reviewing thresholds or using fewer tiers.\")\n",
    "        else:\n",
    "             # If we still have enough bins for 4 labels after sorting unique\n",
    "             print(\"Proceeding with adjusted unique bins for 4 tiers.\")\n",
    "\n",
    "\n",
    "    if len(price_bins) == len(price_labels) + 1: # Ensure we have the right number of bins for labels\n",
    "        df['price_tier'] = pd.cut(df['price'],\n",
    "                                  bins=price_bins,\n",
    "                                  labels=price_labels,\n",
    "                                  right=True,        # (lower_bound, upper_bound]\n",
    "                                  include_lowest=True) # Ensures min value is included\n",
    "\n",
    "        print(\"\\nValue counts for 'price_tier' (%):\")\n",
    "        print(df['price_tier'].value_counts(normalize=True).sort_index() * 100)\n",
    "        \n",
    "        print(\"\\nPrice Tier Definitions Used:\")\n",
    "        for i in range(len(price_labels)):\n",
    "            lower_b = price_bins[i]\n",
    "            if np.isclose(lower_b, -0.01): lower_b = 0.0 # For cleaner display\n",
    "            upper_b = price_bins[i+1]\n",
    "            # Adjust display for the last bin to show it includes the max\n",
    "            inclusive_char = \"<=\" if i < len(price_labels) -1 else \"<=\" \n",
    "            print(f\"  {price_labels[i]}: ${lower_b:.2f} to ${upper_b if i < len(price_labels)-1 else max_price:.2f}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nError: Could not create price tiers. Number of unique bin edges is insufficient for the desired number of labels.\")\n",
    "        print(f\"Final bins considered: {price_bins}\")\n",
    "        print(f\"Labels: {price_labels}\")\n",
    "else:\n",
    "    print(\"Error: 'price' column not found. Cannot create price tiers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Aggregate Features to Create Neighborhood Profiles (for Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Neighbourhood Profiles for Similarity ---\n",
      "\n",
      "Neighbourhood Profiles for Similarity (first 5 rows):\n",
      "  neighbourhood_group neighbourhood  log_price_median  log_price_std  \\\n",
      "0               Bronx      Allerton          4.210781       0.585361   \n",
      "1               Bronx    Baychester          4.330733       0.227715   \n",
      "2               Bronx       Belmont          3.978589       0.702946   \n",
      "3               Bronx     Bronxdale          3.931826       0.359313   \n",
      "4               Bronx   Castle Hill          3.688879       0.477558   \n",
      "\n",
      "   price_median  minimum_nights_median  number_of_reviews_median  \\\n",
      "0          66.5                    2.0                      27.0   \n",
      "1          75.0                    3.0                      11.0   \n",
      "2          52.5                    2.0                       4.5   \n",
      "3          50.0                    2.0                      14.0   \n",
      "4          39.0                    2.0                       0.0   \n",
      "\n",
      "   number_of_reviews_mean  listing_count  room_type_prop_Entire_home_apt  ...  \\\n",
      "0               42.928571             42                        0.380952  ...   \n",
      "1               44.285714              7                        0.428571  ...   \n",
      "2               12.333333             24                        0.125000  ...   \n",
      "3               24.105263             19                        0.421053  ...   \n",
      "4               13.111111              9                        0.444444  ...   \n",
      "\n",
      "   price_tier_prop_Budget  price_tier_prop_Mid-Range  price_tier_prop_Premium  \\\n",
      "0                0.500000                   0.452381                 0.023810   \n",
      "1                0.428571                   0.571429                 0.000000   \n",
      "2                0.625000                   0.291667                 0.083333   \n",
      "3                0.631579                   0.368421                 0.000000   \n",
      "4                0.666667                   0.333333                 0.000000   \n",
      "\n",
      "   price_tier_prop_Upper Premium  host_type_prop_1  host_type_prop_2  \\\n",
      "0                        0.02381          0.452381          0.047619   \n",
      "1                        0.00000          0.285714          0.714286   \n",
      "2                        0.00000          0.500000          0.416667   \n",
      "3                        0.00000          0.894737          0.105263   \n",
      "4                        0.00000          0.222222          0.000000   \n",
      "\n",
      "   host_type_prop_3-5  host_type_prop_6-10  host_type_prop_11-50  \\\n",
      "0            0.500000             0.000000                   0.0   \n",
      "1            0.000000             0.000000                   0.0   \n",
      "2            0.083333             0.000000                   0.0   \n",
      "3            0.000000             0.000000                   0.0   \n",
      "4            0.000000             0.777778                   0.0   \n",
      "\n",
      "   host_type_prop_51+  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Shape of neighbourhood_profiles: (221, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating Neighbourhood Profiles for Similarity ---\")\n",
    "\n",
    "if 'host_type_category' not in df.columns and 'calculated_host_listings_count' in df.columns:\n",
    "    bins_host = [0, 1, 2, 5, 10, 50, df['calculated_host_listings_count'].max() + 1]\n",
    "    labels_host = ['Host_1', 'Host_2', 'Host_3-5', 'Host_6-10', 'Host_11-50', 'Host_51+'] # Renamed for easier column names\n",
    "    df['host_type_category'] = pd.cut(df['calculated_host_listings_count'], bins=bins_host, labels=labels_host, right=True)\n",
    "\n",
    "# Features to aggregate for neighbourhood character\n",
    "agg_functions = {\n",
    "    'log_price': ['median', 'std'], # Median log_price, spread of log_price\n",
    "    'price': ['median'], # Median raw price for easier interpretation\n",
    "    'minimum_nights': ['median'],\n",
    "    'number_of_reviews': ['median', 'mean'], # Median total reviews as quality/establishment proxy\n",
    "    'id': 'count' # Listing density\n",
    "}\n",
    "\n",
    "neighbourhood_profiles = df.groupby(['neighbourhood_group', 'neighbourhood']).agg(agg_functions)\n",
    "\n",
    "# Flatten multi-index columns if any were created by agg\n",
    "neighbourhood_profiles.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in neighbourhood_profiles.columns.values]\n",
    "neighbourhood_profiles.rename(columns={'id_count': 'listing_count'}, inplace=True)\n",
    "\n",
    "\n",
    "# Add room_type proportions\n",
    "room_type_props = df.groupby(['neighbourhood_group', 'neighbourhood'])['room_type'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "room_type_props.columns = [f'room_type_prop_{col.replace(\" \", \"_\").replace(\"/\", \"_\")}' for col in room_type_props.columns] # Clean column names\n",
    "neighbourhood_profiles = neighbourhood_profiles.join(room_type_props)\n",
    "\n",
    "# Add price_tier proportions\n",
    "if 'price_tier' in df.columns:\n",
    "    price_tier_props = df.groupby(['neighbourhood_group', 'neighbourhood'])['price_tier'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "    price_tier_props.columns = [f'price_tier_prop_{col}' for col in price_tier_props.columns]\n",
    "    neighbourhood_profiles = neighbourhood_profiles.join(price_tier_props)\n",
    "\n",
    "# Add host_type_category proportions (optional, but based on your EDA)\n",
    "if 'host_type_category' in df.columns:\n",
    "    host_type_props = df.groupby(['neighbourhood_group', 'neighbourhood'])['host_type_category'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "    host_type_props.columns = [f'host_type_prop_{col}' for col in host_type_props.columns]\n",
    "    neighbourhood_profiles = neighbourhood_profiles.join(host_type_props)\n",
    "\n",
    "\n",
    "neighbourhood_profiles.fillna(0, inplace=True) # Fill any NaNs that might result from unstacking if a category isn't present\n",
    "neighbourhood_profiles = neighbourhood_profiles.reset_index() # Make neighbourhood_group and neighbourhood actual columns\n",
    "\n",
    "print(\"\\nNeighbourhood Profiles for Similarity (first 5 rows):\")\n",
    "print(neighbourhood_profiles.head())\n",
    "print(f\"\\nShape of neighbourhood_profiles: {neighbourhood_profiles.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Define \"Busyness\" for Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Neighbourhood Continuous Busyness Score & New Tiers ---\n",
      "Raw busyness metrics for neighbourhoods (first 5):\n",
      "  neighbourhood_group neighbourhood  avg_availability_365  \\\n",
      "0               Bronx      Allerton            163.666667   \n",
      "1               Bronx    Baychester            157.857143   \n",
      "2               Bronx       Belmont            187.666667   \n",
      "3               Bronx     Bronxdale            145.421053   \n",
      "4               Bronx   Castle Hill            159.333333   \n",
      "\n",
      "   avg_reviews_per_month  listing_density  \n",
      "0               1.615714               42  \n",
      "1               1.891429                7  \n",
      "2               1.573333               24  \n",
      "3               1.614211               19  \n",
      "4               0.616667                9  \n",
      "\n",
      "Composite Busyness Score calculated (first 5 rows with score):\n",
      "  neighbourhood_group neighbourhood  composite_busyness_score\n",
      "0               Bronx      Allerton                  0.124309\n",
      "1               Bronx    Baychester                  0.141948\n",
      "2               Bronx       Belmont                  0.119606\n",
      "3               Bronx     Bronxdale                  0.122242\n",
      "4               Bronx   Castle Hill                  0.046802\n",
      "\n",
      "Descriptive statistics for 'composite_busyness_score':\n",
      "count    221.000000\n",
      "mean       0.122734\n",
      "std        0.069892\n",
      "min        0.000000\n",
      "25%        0.081034\n",
      "50%        0.109421\n",
      "75%        0.149322\n",
      "max        0.413967\n",
      "Name: composite_busyness_score, dtype: float64\n",
      "\n",
      "New 5-tier busyness labels from composite score (value counts):\n",
      "busyness_label_from_score\n",
      "Very Low Busyness     45\n",
      "Low Busyness          44\n",
      "Medium Busyness       44\n",
      "High Busyness         44\n",
      "Very High Busyness    44\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Defining Neighbourhood Continuous Busyness Score & New Tiers ---\")\n",
    "\n",
    "# 1. Calculate raw busyness metrics (This part is the same as your existing cell)\n",
    "neighbourhood_busyness_metrics = df.groupby(['neighbourhood_group', 'neighbourhood']).agg(\n",
    "    avg_availability_365=('availability_365', 'mean'),\n",
    "    avg_reviews_per_month=('reviews_per_month', 'mean'), # Assumes NaNs handled\n",
    "    listing_density=('id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Raw busyness metrics for neighbourhoods (first 5):\")\n",
    "print(neighbourhood_busyness_metrics.head())\n",
    "\n",
    "# 2. Prepare features for the composite score\n",
    "if 'avg_availability_365' in neighbourhood_busyness_metrics.columns:\n",
    "    neighbourhood_busyness_metrics['inverse_avg_availability'] = 1 / (neighbourhood_busyness_metrics['avg_availability_365'] + 0.01)\n",
    "    # These are the features that will make up your composite score\n",
    "    busyness_components = ['inverse_avg_availability', 'avg_reviews_per_month', 'listing_density']\n",
    "else:\n",
    "    busyness_components = ['avg_reviews_per_month', 'listing_density'] \n",
    "    print(\"Warning: 'avg_availability_365' not found, composite score will use fewer features.\")\n",
    "\n",
    "# Ensure selected features are present\n",
    "final_busyness_components = [f for f in busyness_components if f in neighbourhood_busyness_metrics.columns]\n",
    "if not final_busyness_components:\n",
    "    print(\"Error: No valid features found for composite busyness score. Please check column names.\")\n",
    "else:\n",
    "    data_to_scale_for_score = neighbourhood_busyness_metrics[final_busyness_components].copy()\n",
    "\n",
    "    # Safeguard: Impute NaNs if any arose (e.g., from inverse if original availability was -0.01 somehow)\n",
    "    for col in final_busyness_components:\n",
    "        if data_to_scale_for_score[col].isnull().any():\n",
    "            data_to_scale_for_score[col].fillna(data_to_scale_for_score[col].mean(), inplace=True)\n",
    "            print(f\"Warning: NaNs imputed with mean in {col} during busyness score calculation.\")\n",
    "\n",
    "    # 3. Scale these features to a 0-1 range using MinMaxScaler\n",
    "    # This ensures each component can contribute more equally to a simple average score.\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_features_for_score = min_max_scaler.fit_transform(data_to_scale_for_score)\n",
    "    \n",
    "    # Convert back to DataFrame to easily calculate row-wise mean (or weighted sum)\n",
    "    scaled_features_df = pd.DataFrame(scaled_features_for_score, columns=final_busyness_components, index=data_to_scale_for_score.index)\n",
    "\n",
    "    # 4. Calculate Composite Busyness Score (Simple Average Method)\n",
    "    # Higher score means \"busier\" as all components are defined such that higher = busier.\n",
    "    neighbourhood_busyness_metrics['composite_busyness_score'] = scaled_features_df.mean(axis=1)\n",
    "    \n",
    "    print(\"\\nComposite Busyness Score calculated (first 5 rows with score):\")\n",
    "    print(neighbourhood_busyness_metrics[['neighbourhood_group', 'neighbourhood', 'composite_busyness_score']].head())\n",
    "\n",
    "    print(\"\\nDescriptive statistics for 'composite_busyness_score':\")\n",
    "    print(neighbourhood_busyness_metrics['composite_busyness_score'].describe())\n",
    "\n",
    "    # 5. Optional: Create new categorical busyness tiers based on this continuous score\n",
    "    # For example, 5 tiers (quintiles) for more granularity than your previous 3 K-Means clusters\n",
    "    busyness_score_labels_5tiers = ['Very Low Busyness', 'Low Busyness', 'Medium Busyness', 'High Busyness', 'Very High Busyness']\n",
    "    try:\n",
    "        neighbourhood_busyness_metrics['busyness_label_from_score'] = pd.qcut(\n",
    "            neighbourhood_busyness_metrics['composite_busyness_score'],\n",
    "            q=5, # For 5 quintiles/tiers\n",
    "            labels=busyness_score_labels_5tiers,\n",
    "            duplicates='drop' # Important if many neighborhoods have similar scores leading to non-unique bin edges\n",
    "        )\n",
    "        print(\"\\nNew 5-tier busyness labels from composite score (value counts):\")\n",
    "        print(neighbourhood_busyness_metrics['busyness_label_from_score'].value_counts().sort_index())\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not create 5-tier labels with pd.qcut due to score distribution (e.g., too few unique scores for 5 quantiles): {e}\")\n",
    "        print(\"Consider using fewer quantiles or manual binning if this occurs, or just use the continuous score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Combine Similarity Profiles with Busyness Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combining Neighbourhood Similarity Profiles with NEW Busyness Information ---\n",
      "Found 'busyness_label_from_score' to merge.\n",
      "\n",
      "Final Combined Neighbourhood Profiles (with new busyness score/labels - first 5 rows):\n",
      "  neighbourhood_group neighbourhood  log_price_median  log_price_std  \\\n",
      "0               Bronx      Allerton          4.210781       0.585361   \n",
      "1               Bronx    Baychester          4.330733       0.227715   \n",
      "2               Bronx       Belmont          3.978589       0.702946   \n",
      "3               Bronx     Bronxdale          3.931826       0.359313   \n",
      "4               Bronx   Castle Hill          3.688879       0.477558   \n",
      "\n",
      "   price_median  minimum_nights_median  number_of_reviews_median  \\\n",
      "0          66.5                    2.0                      27.0   \n",
      "1          75.0                    3.0                      11.0   \n",
      "2          52.5                    2.0                       4.5   \n",
      "3          50.0                    2.0                      14.0   \n",
      "4          39.0                    2.0                       0.0   \n",
      "\n",
      "   number_of_reviews_mean  listing_count  room_type_prop_Entire_home_apt  ...  \\\n",
      "0               42.928571             42                        0.380952  ...   \n",
      "1               44.285714              7                        0.428571  ...   \n",
      "2               12.333333             24                        0.125000  ...   \n",
      "3               24.105263             19                        0.421053  ...   \n",
      "4               13.111111              9                        0.444444  ...   \n",
      "\n",
      "   price_tier_prop_Premium  price_tier_prop_Upper Premium  host_type_prop_1  \\\n",
      "0                 0.023810                        0.02381          0.452381   \n",
      "1                 0.000000                        0.00000          0.285714   \n",
      "2                 0.083333                        0.00000          0.500000   \n",
      "3                 0.000000                        0.00000          0.894737   \n",
      "4                 0.000000                        0.00000          0.222222   \n",
      "\n",
      "   host_type_prop_2  host_type_prop_3-5  host_type_prop_6-10  \\\n",
      "0          0.047619            0.500000             0.000000   \n",
      "1          0.714286            0.000000             0.000000   \n",
      "2          0.416667            0.083333             0.000000   \n",
      "3          0.105263            0.000000             0.000000   \n",
      "4          0.000000            0.000000             0.777778   \n",
      "\n",
      "   host_type_prop_11-50  host_type_prop_51+  composite_busyness_score  \\\n",
      "0                   0.0                 0.0                  0.124309   \n",
      "1                   0.0                 0.0                  0.141948   \n",
      "2                   0.0                 0.0                  0.119606   \n",
      "3                   0.0                 0.0                  0.122242   \n",
      "4                   0.0                 0.0                  0.046802   \n",
      "\n",
      "   busyness_label_from_score  \n",
      "0              High Busyness  \n",
      "1              High Busyness  \n",
      "2            Medium Busyness  \n",
      "3              High Busyness  \n",
      "4          Very Low Busyness  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Shape of final_neighbourhood_profiles_df: (221, 24)\n",
      "\n",
      "Check for any missing new busyness information after merge:\n",
      "Missing 'composite_busyness_score': 0\n",
      "Missing 'busyness_label_from_score': 0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Combining Neighbourhood Similarity Profiles with NEW Busyness Information ---\")\n",
    "\n",
    "if 'neighbourhood_profiles' in locals() or 'neighbourhood_profiles' in globals():\n",
    "    if 'neighbourhood_busyness_metrics' in locals() or 'neighbourhood_busyness_metrics' in globals():\n",
    "        \n",
    "        # Define columns to merge from neighbourhood_busyness_metrics\n",
    "        # These should be your new busyness metrics\n",
    "        columns_to_merge = ['neighbourhood_group', 'neighbourhood', 'composite_busyness_score']\n",
    "        \n",
    "        # Check if you created the new N-tier label and add it for merging\n",
    "        if 'busyness_label_from_score' in neighbourhood_busyness_metrics.columns:\n",
    "            columns_to_merge.append('busyness_label_from_score')\n",
    "            print(\"Found 'busyness_label_from_score' to merge.\")\n",
    "        elif 'busyness_label_5tiers' in neighbourhood_busyness_metrics.columns: # Alternative name used in example\n",
    "            columns_to_merge.append('busyness_label_5tiers')\n",
    "            print(\"Found 'busyness_label_5tiers' to merge.\")\n",
    "        else:\n",
    "            print(\"Note: New N-tier busyness label (e.g., 'busyness_label_from_score') not found in neighbourhood_busyness_metrics. Merging continuous score only.\")\n",
    "\n",
    "        # Ensure the key columns for merging exist\n",
    "        actual_cols_to_merge = [col for col in columns_to_merge if col in neighbourhood_busyness_metrics.columns]\n",
    "        if 'neighbourhood' not in actual_cols_to_merge or 'neighbourhood_group' not in actual_cols_to_merge:\n",
    "            print(\"Error: 'neighbourhood' or 'neighbourhood_group' missing in neighbourhood_busyness_metrics for merging.\")\n",
    "        else:\n",
    "            neighbourhood_busyness_to_merge = neighbourhood_busyness_metrics[actual_cols_to_merge].drop_duplicates(subset=['neighbourhood_group', 'neighbourhood'])\n",
    "\n",
    "            # Create the final DataFrame.\n",
    "            # If 'final_neighbourhood_profiles_df' might exist from a previous run with old busyness columns,\n",
    "            # it's cleaner to merge with the base 'neighbourhood_profiles' which only has character features.\n",
    "            final_neighbourhood_profiles_df = pd.merge(\n",
    "                neighbourhood_profiles, # This should be your profiles *without* any old busyness columns\n",
    "                neighbourhood_busyness_to_merge,\n",
    "                on=['neighbourhood_group', 'neighbourhood'],\n",
    "                how='left' \n",
    "            )\n",
    "\n",
    "            print(\"\\nFinal Combined Neighbourhood Profiles (with new busyness score/labels - first 5 rows):\")\n",
    "            print(final_neighbourhood_profiles_df.head())\n",
    "            print(f\"\\nShape of final_neighbourhood_profiles_df: {final_neighbourhood_profiles_df.shape}\")\n",
    "            \n",
    "            print(\"\\nCheck for any missing new busyness information after merge:\")\n",
    "            if 'composite_busyness_score' in final_neighbourhood_profiles_df.columns:\n",
    "                print(f\"Missing 'composite_busyness_score': {final_neighbourhood_profiles_df['composite_busyness_score'].isnull().sum()}\")\n",
    "            if 'busyness_label_from_score' in final_neighbourhood_profiles_df.columns: # Or 'busyness_label_5tiers'\n",
    "                print(f\"Missing 'busyness_label_from_score': {final_neighbourhood_profiles_df['busyness_label_from_score'].isnull().sum()}\")\n",
    "            elif 'busyness_label_5tiers' in final_neighbourhood_profiles_df.columns:\n",
    "                 print(f\"Missing 'busyness_label_5tiers': {final_neighbourhood_profiles_df['busyness_label_5tiers'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Error: 'neighbourhood_busyness_metrics' DataFrame (with new scores/labels) not found.\")\n",
    "else:\n",
    "    print(\"Error: 'neighbourhood_profiles' DataFrame (character profiles) not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature Selection and Scaling for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Selecting and Scaling Features for KNN Similarity ---\n",
      "Using these 18 features for KNN similarity: ['host_type_prop_1', 'host_type_prop_11-50', 'host_type_prop_2', 'host_type_prop_3-5', 'host_type_prop_51+', 'host_type_prop_6-10', 'listing_count', 'log_price_median', 'log_price_std', 'minimum_nights_median', 'number_of_reviews_mean', 'number_of_reviews_median', 'price_tier_prop_Budget', 'price_tier_prop_Mid-Range', 'price_tier_prop_Premium', 'room_type_prop_Entire_home_apt', 'room_type_prop_Private_room', 'room_type_prop_Shared_room']\n",
      "\n",
      "Shape of scaled features for KNN: (221, 18)\n",
      "Scaled features (first row example): [-0.82373718 -0.25850706 -0.72302177  2.12973271 -0.23393207 -0.40643778\n",
      " -0.33506963 -0.6290947   0.1013179  -0.30285419  1.28085333  1.29846227\n",
      "  0.59921022 -0.04477275 -0.67913045 -0.51235558  0.69540609 -0.50440547]\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Selecting and Scaling Features for KNN Similarity ---\")\n",
    "\n",
    "# Define columns from final_neighbourhood_profiles_df to be used for calculating similarity.\n",
    "# These should be features describing the neighborhood's character.\n",
    "# Exclude identifiers (neighbourhood, neighbourhood_group) and the busyness label/cluster itself.\n",
    "\n",
    "# Recommended similarity features based on EDA and profile creation:\n",
    "similarity_feature_columns = [\n",
    "    'log_price_median',         # Typical price level (log-transformed)\n",
    "    'log_price_std',            # Price variability within the neighborhood\n",
    "    'minimum_nights_median',    # Typical minimum stay\n",
    "    'number_of_reviews_median', # Proxy for typical listing establishment/perceived quality\n",
    "    'number_of_reviews_mean',\n",
    "    'listing_count',            # Can also be part of neighborhood character (small vs. large inventory)\n",
    "    \n",
    "    # Room type proportions\n",
    "    'room_type_prop_Entire_home_apt',\n",
    "    'room_type_prop_Private_room',\n",
    "    'room_type_prop_Shared_room',\n",
    "    \n",
    "    # Price tier proportions\n",
    "    'price_tier_prop_Budget',\n",
    "    'price_tier_prop_Mid-Range',\n",
    "    'price_tier_prop_Premium',\n",
    "    'price_tier_prop_Upper_Premium',\n",
    "    \n",
    "    # Host type proportions\n",
    "    'host_type_prop_1',\n",
    "    'host_type_prop_2',\n",
    "    'host_type_prop_3-5',\n",
    "    'host_type_prop_6-10',\n",
    "    'host_type_prop_11-50',\n",
    "    'host_type_prop_51+'\n",
    "]\n",
    "similarity_feature_columns.extend([col for col in final_neighbourhood_profiles_df.columns if 'host_type_prop_' in col])\n",
    "similarity_feature_columns = sorted(list(set(similarity_feature_columns))) # Ensure uniqueness and order\n",
    "\n",
    "# Verify that these columns exist in your DataFrame\n",
    "existing_similarity_features = [col for col in similarity_feature_columns if col in final_neighbourhood_profiles_df.columns]\n",
    "\n",
    "if not existing_similarity_features:\n",
    "    print(\"Error: No similarity feature columns found in 'final_neighbourhood_profiles_df'. Please check column names.\")\n",
    "    features_scaled = None # Ensure this variable is defined for later checks\n",
    "else:\n",
    "    print(f\"Using these {len(existing_similarity_features)} features for KNN similarity: {existing_similarity_features}\")\n",
    "    \n",
    "    features_for_knn = final_neighbourhood_profiles_df[existing_similarity_features].copy()\n",
    "    \n",
    "    # Fill any potential NaNs in these selected features (e.g., if a proportion was all NaN and then 0)\n",
    "    # A good practice before scaling, though your aggregation should handle most.\n",
    "    features_for_knn.fillna(features_for_knn.mean(), inplace=True) # Impute with mean if any NaNs persist\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features_for_knn)\n",
    "    \n",
    "    print(\"\\nShape of scaled features for KNN:\", features_scaled.shape)\n",
    "    print(\"Scaled features (first row example):\", features_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fit KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fitting KNN Model ---\n",
      "KNN model fitted with k=11 and 'euclidean' metric.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Fitting KNN Model ---\")\n",
    "\n",
    "knn_model = None # Initialize\n",
    "if 'features_scaled' in locals() and features_scaled is not None and features_scaled.shape[0] > 0:\n",
    "    # Number of neighbors: target itself + up to 10 others. Max N-1 if N < 11.\n",
    "    n_neighbors_knn = min(11, features_scaled.shape[0]) \n",
    "\n",
    "    knn_model = NearestNeighbors(n_neighbors=n_neighbors_knn, metric='euclidean') # 'cosine' is also a good option\n",
    "    knn_model.fit(features_scaled)\n",
    "    \n",
    "    print(f\"KNN model fitted with k={n_neighbors_knn} and '{knn_model.metric}' metric.\")\n",
    "else:\n",
    "    print(\"Error: Scaled features for KNN ('features_scaled') not available or empty. KNN model not fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Develop Recommendation Logic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Defining Recommendation Logic Function (v2 - for Continuous Busyness Score) ---\n",
      "\n",
      "Recommendation function 'get_neighbourhood_recommendations' (v2 - for continuous score) is now defined.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Defining Recommendation Logic Function (v2 - for Continuous Busyness Score) ---\")\n",
    "\n",
    "def get_neighbourhood_recommendations_v2(target_neighbourhood_name, \n",
    "                                        target_group_name,\n",
    "                                        df_profiles, # This is your final_neighbourhood_profiles_df\n",
    "                                        model_knn, \n",
    "                                        all_scaled_features, # Scaled features used for KNN\n",
    "                                        num_recommendations=3,\n",
    "                                        busyness_score_column='composite_busyness_score', # Use your new continuous score column\n",
    "                                        busyness_threshold_factor=1.0): \n",
    "\n",
    "    recommendations_df = pd.DataFrame()\n",
    "    \n",
    "    target_profile_matches = df_profiles[\n",
    "        (df_profiles['neighbourhood'] == target_neighbourhood_name) &\n",
    "        (df_profiles['neighbourhood_group'] == target_group_name)\n",
    "    ]\n",
    "\n",
    "    if target_profile_matches.empty:\n",
    "        print(f\"Error: Target neighbourhood '{target_neighbourhood_name}' in group '{target_group_name}' not found.\")\n",
    "        return recommendations_df\n",
    "\n",
    "    target_index = target_profile_matches.index[0]\n",
    "    \n",
    "    if busyness_score_column not in target_profile_matches.columns:\n",
    "        print(f\"Error: Busyness score column '{busyness_score_column}' not found in profiles.\")\n",
    "        return recommendations_df\n",
    "        \n",
    "    target_busyness_score = target_profile_matches[busyness_score_column].iloc[0]\n",
    "    \n",
    "    print(f\"\\nTarget: {target_neighbourhood_name} ({target_group_name}), Original Busyness Score: {target_busyness_score:.3f}\")\n",
    "\n",
    "    # Define the threshold for an alternative to be \"less busy\"\n",
    "    # If a higher score means \"busier\", then we want alternatives with a score *lower* than the target's.\n",
    "    max_acceptable_busyness_score = target_busyness_score * busyness_threshold_factor\n",
    "    \n",
    "    # If busyness_threshold_factor is 1.0, it means we want strictly less.\n",
    "    # If target_busyness_score is very low, max_acceptable_busyness_score could become 0 or negative if not handled.\n",
    "    # Ensure max_acceptable_busyness_score doesn't go below a logical minimum (e.g. 0 if scores are non-negative)\n",
    "    if busyness_threshold_factor == 1.0: # Strictly less than target\n",
    "        max_acceptable_busyness_score = target_busyness_score - 1e-6 # A very small epsilon to ensure it's strictly less\n",
    "    \n",
    "    # If target score is already very low, finding something \"less busy\" might be hard or impossible.\n",
    "    # You might add a check here: if target_busyness_score < some_absolute_low_threshold: print \"Target is already very low busyness\"\n",
    "    \n",
    "    print(f\"Searching for alternatives with busyness score < {max_acceptable_busyness_score:.3f} (target score was {target_busyness_score:.3f})\")\n",
    "        \n",
    "    target_features_scaled_for_knn = all_scaled_features[target_index].reshape(1, -1)\n",
    "    distances, indices = model_knn.kneighbors(target_features_scaled_for_knn)\n",
    "    \n",
    "    neighbor_profiles_df = df_profiles.iloc[indices[0]].copy()\n",
    "    neighbor_profiles_df['similarity_distance'] = distances[0]\n",
    "    \n",
    "    recommendations_df = neighbor_profiles_df[\n",
    "        (neighbor_profiles_df['neighbourhood'] != target_neighbourhood_name) & \n",
    "        (neighbor_profiles_df['neighbourhood_group'] == target_group_name) &\n",
    "        (neighbor_profiles_df[busyness_score_column] < max_acceptable_busyness_score) \n",
    "    ].sort_values(by='similarity_distance', ascending=True).head(num_recommendations)\n",
    "    \n",
    "    if recommendations_df.empty:\n",
    "        print(f\"No suitable less busy (score < {max_acceptable_busyness_score:.3f}), similar neighbourhoods found in '{target_group_name}' for '{target_neighbourhood_name}'.\")\n",
    "\n",
    "    return recommendations_df\n",
    "\n",
    "# Define the function in your notebook by running this cell\n",
    "get_neighbourhood_recommendations = get_neighbourhood_recommendations_v2 # Overwrite or use new name\n",
    "\n",
    "print(\"\\nRecommendation function 'get_neighbourhood_recommendations' (v2 - for continuous score) is now defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Recommendation Logic with Continuous Busyness Score ---\n",
      "\n",
      "--- Test Case 1: Target: Midtown, Manhattan ---\n",
      "\n",
      "Target: Midtown (Manhattan), Original Busyness Score: 0.193\n",
      "Searching for alternatives with busyness score < 0.154 (target score was 0.193)\n",
      "\n",
      "Recommended less busy (score < target_score * 0.8), similar neighbourhoods in Manhattan for Midtown:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>busyness_label_from_score</th>\n",
       "      <th>composite_busyness_score</th>\n",
       "      <th>similarity_distance</th>\n",
       "      <th>price_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Kips Bay</td>\n",
       "      <td>Low Busyness</td>\n",
       "      <td>0.096633</td>\n",
       "      <td>3.031839</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>West Village</td>\n",
       "      <td>High Busyness</td>\n",
       "      <td>0.121361</td>\n",
       "      <td>3.579690</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Gramercy</td>\n",
       "      <td>Low Busyness</td>\n",
       "      <td>0.093901</td>\n",
       "      <td>3.621641</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neighbourhood busyness_label_from_score  composite_busyness_score  \\\n",
       "108      Kips Bay              Low Busyness                  0.096633   \n",
       "126  West Village             High Busyness                  0.121361   \n",
       "103      Gramercy              Low Busyness                  0.093901   \n",
       "\n",
       "     similarity_distance  price_median  \n",
       "108             3.031839         152.0  \n",
       "126             3.579690         200.0  \n",
       "103             3.621641         165.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Case 2: Target: Allerton, Bronx ---\n",
      "\n",
      "Target: Allerton (Bronx), Original Busyness Score: 0.124\n",
      "Searching for alternatives with busyness score < 0.124 (target score was 0.124)\n",
      "No suitable less busy (score < 0.124), similar neighbourhoods found in 'Bronx' for 'Allerton'.\n",
      "Further check: No recommendations returned by the function for Allerton.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Recommendation Logic with Continuous Busyness Score ---\")\n",
    "\n",
    "if not all(var in locals() or var in globals() for var in ['final_neighbourhood_profiles_df', 'knn_model', 'features_scaled', 'get_neighbourhood_recommendations']):\n",
    "    print(\"ERROR: One or more required variables not found. Run previous cells defining these elements.\")\n",
    "elif 'composite_busyness_score' not in final_neighbourhood_profiles_df.columns:\n",
    "    print(\"ERROR: 'composite_busyness_score' column not found in 'final_neighbourhood_profiles_df'. Please run the cell that calculates this score.\")\n",
    "else:\n",
    "    # --- Test Case 1: Target 'Midtown' in 'Manhattan' ---\n",
    "    target_n1 = 'Midtown'\n",
    "    target_g1 = 'Manhattan'\n",
    "    print(f\"\\n--- Test Case 1: Target: {target_n1}, {target_g1} ---\")\n",
    "\n",
    "    # Define how much \"less busy\" you want the alternatives to be.\n",
    "    # factor = 1.0 means strictly less busy than the target.\n",
    "    # factor = 0.9 means at most 90% of the target's busyness score (i.e., at least 10% less busy).\n",
    "    # factor = 0.8 means at most 80% of the target's busyness score (i.e., at least 20% less busy).\n",
    "    threshold_factor_for_midtown = 0.8 \n",
    "\n",
    "    recommendations1 = get_neighbourhood_recommendations( # Assuming you renamed/updated your function\n",
    "        target_neighbourhood_name=target_n1,\n",
    "        target_group_name=target_g1,\n",
    "        df_profiles=final_neighbourhood_profiles_df,\n",
    "        model_knn=knn_model,\n",
    "        all_scaled_features=features_scaled,\n",
    "        num_recommendations=3,\n",
    "        busyness_score_column='composite_busyness_score', # Use the continuous score column\n",
    "        busyness_threshold_factor=threshold_factor_for_midtown \n",
    "    )\n",
    "\n",
    "    if not recommendations1.empty:\n",
    "        print(f\"\\nRecommended less busy (score < target_score * {threshold_factor_for_midtown}), similar neighbourhoods in {target_g1} for {target_n1}:\")\n",
    "        # Display relevant columns, including the new score and your N-tier label if you created it\n",
    "        cols_to_display = ['neighbourhood', 'composite_busyness_score', 'similarity_distance', 'price_median']\n",
    "        if 'busyness_label_from_score' in recommendations1.columns: # If you created the 5-tier label\n",
    "            cols_to_display.insert(1, 'busyness_label_from_score')\n",
    "        elif 'busyness_label_5tiers' in recommendations1.columns: # Alternative name\n",
    "             cols_to_display.insert(1, 'busyness_label_5tiers')\n",
    "        display(recommendations1[cols_to_display])\n",
    "    else:\n",
    "        # The function get_neighbourhood_recommendations should have printed why no recommendations were made.\n",
    "        # (e.g., \"No suitable less busy ... found\")\n",
    "        # You could add a generic message here if needed, but it might be redundant.\n",
    "        print(f\"Further check: No recommendations returned by the function for {target_n1}.\")\n",
    "\n",
    "\n",
    "    # --- Test Case 2: Target 'Allerton' in 'Bronx' ---\n",
    "    # Allerton was previously 'Supply Constrained/Busy' with the K-Means labels.\n",
    "    # Let's see how it behaves with the continuous score.\n",
    "    target_n2 = 'Allerton'\n",
    "    target_g2 = 'Bronx'\n",
    "    print(f\"\\n--- Test Case 2: Target: {target_n2}, {target_g2} ---\")\n",
    "    \n",
    "    threshold_factor_for_allerton = 1.0 # Strictly less busy\n",
    "\n",
    "    recommendations2 = get_neighbourhood_recommendations(\n",
    "        target_neighbourhood_name=target_n2,\n",
    "        target_group_name=target_g2,\n",
    "        df_profiles=final_neighbourhood_profiles_df,\n",
    "        model_knn=knn_model,\n",
    "        all_scaled_features=features_scaled,\n",
    "        num_recommendations=3,\n",
    "        busyness_score_column='composite_busyness_score',\n",
    "        busyness_threshold_factor=threshold_factor_for_allerton\n",
    "    )\n",
    "\n",
    "    if not recommendations2.empty:\n",
    "        print(f\"\\nRecommended less busy (score < target_score * {threshold_factor_for_allerton}), similar neighbourhoods in {target_g2} for {target_n2}:\")\n",
    "        cols_to_display = ['neighbourhood', 'composite_busyness_score', 'similarity_distance', 'price_median']\n",
    "        if 'busyness_label_from_score' in recommendations2.columns:\n",
    "            cols_to_display.insert(1, 'busyness_label_from_score')\n",
    "        elif 'busyness_label_5tiers' in recommendations2.columns:\n",
    "             cols_to_display.insert(1, 'busyness_label_5tiers')\n",
    "        display(recommendations2[cols_to_display])\n",
    "    else:\n",
    "        print(f\"Further check: No recommendations returned by the function for {target_n2}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Imports for Interactive Demo (and PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from sklearn.decomposition import PCA # For the PCA plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if 'final_neighbourhood_profiles_df' not in locals() or 'knn_model' not in locals() or 'features_scaled' not in locals() or 'get_neighbourhood_recommendations' not in locals():\n",
    "    print(\"WARNING: Key components (DataFrame, KNN model, scaled features, or recommendation function) not found.\")\n",
    "    print(\"This script might not run correctly without them. Ensure they are loaded/defined from your previous work.\")\n",
    "    # Create minimal dummies for script validation if run by the tool without prior state\n",
    "    final_neighbourhood_profiles_df = pd.DataFrame({\n",
    "        'neighbourhood_group': ['Manhattan', 'Manhattan', 'Manhattan', 'Brooklyn', 'Brooklyn'],\n",
    "        'neighbourhood': ['Midtown', 'Harlem', 'Chelsea', 'Williamsburg', 'Bushwick'],\n",
    "        'log_price_median': np.random.rand(5) * 2 + 4,\n",
    "        'busyness_label': ['High Density/Saturated', 'Active & Available/Less Busy', 'Supply Constrained/Busy', 'Supply Constrained/Busy', 'Active & Available/Less Busy']\n",
    "    })\n",
    "    # Dummy features_scaled for PCA plotting (rows must match df)\n",
    "    if 'features_scaled' not in locals() or features_scaled is None or features_scaled.shape[0] != len(final_neighbourhood_profiles_df) :\n",
    "      features_scaled = StandardScaler().fit_transform(np.random.rand(len(final_neighbourhood_profiles_df), 5)) # Dummy with 5 features\n",
    "    # Dummy knn_model\n",
    "    if 'knn_model' not in locals() or knn_model is None:\n",
    "      from sklearn.neighbors import NearestNeighbors\n",
    "      knn_model = NearestNeighbors(n_neighbors=3).fit(features_scaled)\n",
    "    # Dummy recommendation function\n",
    "    if 'get_neighbourhood_recommendations' not in locals():\n",
    "        def get_neighbourhood_recommendations(target_neighbourhood_name, target_group_name, df_profiles, model_knn, all_scaled_features, **kwargs):\n",
    "            print(f\"Dummy call for {target_neighbourhood_name}, {target_group_name}. In real use, this would return recommendations.\")\n",
    "            return pd.DataFrame({'neighbourhood': ['Dummy Rec 1', 'Dummy Rec 2'], 'busyness_label': ['Active & Available/Less Busy']*2, 'similarity_distance': [0.1,0.2]})\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Prepare Data for PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing 2D coordinates for PCA plot ---\n",
      "PCA transformation complete for plotting.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Preparing 2D coordinates for PCA plot ---\")\n",
    "pca_plot_coords = None # Initialized to None\n",
    "if 'features_scaled' in locals() and features_scaled is not None and features_scaled.shape[0] > 0 :\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pca_plot_coords = pca.fit_transform(features_scaled) # This is where it's assigned\n",
    "    print(\"PCA transformation complete for plotting.\")\n",
    "    final_neighbourhood_profiles_df['pca1'] = pca_plot_coords[:, 0]\n",
    "    final_neighbourhood_profiles_df['pca2'] = pca_plot_coords[:, 1]\n",
    "else:\n",
    "    print(\"Error: 'features_scaled' not available or empty. Cannot prepare PCA plot coordinates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Setup ipywidgets for Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up Interactive Widgets with Dependent Dropdown ---\n",
      "Widgets created and dependent dropdown logic is set up.\n",
      "Please select a Neighbourhood Group; the Neighbourhood dropdown will then populate.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Setting up Interactive Widgets with Dependent Dropdown ---\")\n",
    "\n",
    "# 1. Create the widgets\n",
    "group_options = ['-- Select a N\\'hood Group --'] + sorted(final_neighbourhood_profiles_df[\"neighbourhood_group\"].unique())\n",
    "group_dropdown = widgets.Dropdown(\n",
    "    options=group_options,\n",
    "    value=group_options[0], # Default to the prompt\n",
    "    description=\"N'hood Group:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "neighbourhood_dropdown = widgets.Dropdown(\n",
    "    options=['-- Select a Neighbourhood --'], # Initial prompt\n",
    "    value='-- Select a Neighbourhood --',\n",
    "    description=\"Neighbourhood:\",\n",
    "    disabled=True, # Start disabled\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description=\"🔍 Find Alternatives\",\n",
    "    button_style='primary',\n",
    "    tooltip='Click to get recommendations',\n",
    "    icon='search',\n",
    "    layout=widgets.Layout(width=\"auto\", margin='10px 0 0 0')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# 2. Define the single function to update the neighbourhood_dropdown\n",
    "def on_group_select_update_neighbourhood_options(change):\n",
    "    \"\"\"\n",
    "    This function is called when the value of group_dropdown changes.\n",
    "    It updates the options in neighbourhood_dropdown based on the selected group.\n",
    "    \"\"\"\n",
    "    selected_group = change.new # The new value of the group_dropdown\n",
    "\n",
    "    # Always reset neighbourhood_dropdown to its initial prompt state first\n",
    "    current_neighbourhood_options = ['-- Select a Neighbourhood --']\n",
    "    neighbourhood_dropdown.options = current_neighbourhood_options\n",
    "    neighbourhood_dropdown.value = current_neighbourhood_options[0] # Set to prompt\n",
    "    \n",
    "    if selected_group and selected_group != '-- Select a N\\'hood Group --': # If a valid group is selected\n",
    "        # Filter neighbourhoods for the selected group\n",
    "        neighbourhoods_in_group = sorted(\n",
    "            final_neighbourhood_profiles_df[final_neighbourhood_profiles_df[\"neighbourhood_group\"] == selected_group][\"neighbourhood\"].unique()\n",
    "        )\n",
    "        \n",
    "        if neighbourhoods_in_group:\n",
    "            # Update options and enable the dropdown\n",
    "            neighbourhood_dropdown.options = current_neighbourhood_options + neighbourhoods_in_group\n",
    "            neighbourhood_dropdown.disabled = False\n",
    "        else:\n",
    "            # No neighbourhoods found for this group (should ideally not happen with real data)\n",
    "            neighbourhood_dropdown.disabled = True\n",
    "    else:\n",
    "        # If the prompt \"-- Select a N'hood Group --\" is re-selected, disable neighbourhood_dropdown\n",
    "        neighbourhood_dropdown.disabled = True\n",
    "    \n",
    "    # Clear any previous results shown in the output_area when the group changes\n",
    "    output_area.clear_output()\n",
    "\n",
    "# 3. Link the group_dropdown's 'value' change event to the update function\n",
    "group_dropdown.observe(on_group_select_update_neighbourhood_options, names='value')\n",
    "\n",
    "print(\"Widgets created and dependent dropdown logic is set up.\")\n",
    "print(\"Please select a Neighbourhood Group; the Neighbourhood dropdown will then populate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Define the Main Action Function (triggered by button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Defining Main Action Function for Button Click (Using Continuous Score) ---\n",
      "Action function 'on_find_alternatives_clicked' (Updated for Continuous Score) defined and linked to button.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Defining Main Action Function for Button Click (Using Continuous Score) ---\")\n",
    "\n",
    "def on_find_alternatives_clicked(b): # b is the button event\n",
    "    with output_area:\n",
    "        output_area.clear_output(wait=True) \n",
    "        \n",
    "        try: \n",
    "            selected_group = group_dropdown.value\n",
    "            selected_neighbourhood = neighbourhood_dropdown.value\n",
    "\n",
    "            if not selected_group or selected_group == '-- Select a N\\'hood Group --' or \\\n",
    "               not selected_neighbourhood or selected_neighbourhood == '-- Select a Neighbourhood --':\n",
    "                display(Markdown(\"<font color='red'>**Error:** Please select a valid Neighbourhood Group and Neighbourhood.</font>\"))\n",
    "                return\n",
    "\n",
    "            display(Markdown(f\"### Processing: Recommending for **{selected_neighbourhood}** in **{selected_group}**...\"))\n",
    "            \n",
    "            target_profile = final_neighbourhood_profiles_df[\n",
    "                (final_neighbourhood_profiles_df['neighbourhood_group'] == selected_group) &\n",
    "                (final_neighbourhood_profiles_df['neighbourhood'] == selected_neighbourhood)\n",
    "            ]\n",
    "            \n",
    "            if target_profile.empty:\n",
    "                display(Markdown(f\"<font color='red'>Error: Profile for {selected_neighbourhood} in {selected_group} not found.</font>\"))\n",
    "                return\n",
    "            \n",
    "            # Use the continuous busyness score\n",
    "            target_busyness_score = target_profile['composite_busyness_score'].iloc[0]\n",
    "            \n",
    "            # Define your busyness_threshold_factor for the call\n",
    "            # Example: 1.0 means strictly less busy. 0.9 means at least 10% less busy.\n",
    "            # You can make this dynamic based on target_busyness_score or selected_group if desired\n",
    "            threshold_factor = 0.85 \n",
    "\n",
    "            recommendations = get_neighbourhood_recommendations( # Assuming this is now the v2 function\n",
    "                target_neighbourhood_name=selected_neighbourhood,\n",
    "                target_group_name=selected_group,\n",
    "                df_profiles=final_neighbourhood_profiles_df,\n",
    "                model_knn=knn_model,\n",
    "                all_scaled_features=features_scaled,\n",
    "                num_recommendations=3,\n",
    "                busyness_score_column='composite_busyness_score', # Pass the correct column name\n",
    "                busyness_threshold_factor=threshold_factor \n",
    "            )\n",
    "\n",
    "            display(Markdown(f\"#### Selected: **{selected_neighbourhood}** ({selected_group}) - Busyness Score: *{target_busyness_score:.3f}*\"))\n",
    "\n",
    "            if not recommendations.empty:\n",
    "                display(Markdown(\"#### ✅ Recommended Less Busy, Similar Alternatives:\"))\n",
    "                # Display relevant columns, including the new score\n",
    "                cols_to_show = ['neighbourhood', 'composite_busyness_score', 'similarity_distance', 'price_median']\n",
    "                if 'busyness_label_from_score' in recommendations.columns: # If you created N-tier labels from score\n",
    "                    cols_to_show.insert(1, 'busyness_label_from_score')\n",
    "                display(recommendations[cols_to_show])\n",
    "            else:\n",
    "                # Check if the target itself was already very \"less busy\"\n",
    "                # (The get_neighbourhood_recommendations function handles its own print for this,\n",
    "                # but we add a clear message here too if no recs were returned for other reasons)\n",
    "                very_low_busyness_cutoff = final_neighbourhood_profiles_df['composite_busyness_score'].quantile(0.25) # Example: bottom 25%\n",
    "                if target_busyness_score < very_low_busyness_cutoff and (target_busyness_score * threshold_factor) < target_busyness_score : # and we were actually looking for something less busy\n",
    "                    display(Markdown(f\"<font color='green'>'{selected_neighbourhood}' already has a low busyness score ({target_busyness_score:.3f}). No significantly less busy, similar alternatives were found.</font>\"))\n",
    "                else:\n",
    "                    display(Markdown(f\"<font color='orange'>⚠️ No suitable less busy, similar neighbourhoods found in {selected_group} for {selected_neighbourhood} with the defined criteria (busyness score < {target_busyness_score * threshold_factor:.3f}).</font>\"))\n",
    "\n",
    "            # --- Display PCA Plot ---\n",
    "            if 'pca1' in final_neighbourhood_profiles_df.columns and 'pca2' in final_neighbourhood_profiles_df.columns:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                \n",
    "                # For coloring/styling the PCA plot, you can use your new N-tier busyness label\n",
    "                # if you created one (e.g., 'busyness_label_from_score') or just style by neighbourhood_group\n",
    "                hue_column_pca = 'busyness_label_from_score' if 'busyness_label_from_score' in final_neighbourhood_profiles_df.columns else 'neighbourhood_group'\n",
    "                \n",
    "                sns.scatterplot(\n",
    "                    x=final_neighbourhood_profiles_df['pca1'], \n",
    "                    y=final_neighbourhood_profiles_df['pca2'],\n",
    "                    hue=final_neighbourhood_profiles_df[hue_column_pca], \n",
    "                    style=final_neighbourhood_profiles_df['neighbourhood_group'],\n",
    "                    # palette=palette_pca, # Add if using N-tier labels with a custom palette\n",
    "                    alpha=0.6, s=50\n",
    "                )\n",
    "                \n",
    "                selected_coords_df = final_neighbourhood_profiles_df[\n",
    "                    (final_neighbourhood_profiles_df['neighbourhood'] == selected_neighbourhood) &\n",
    "                    (final_neighbourhood_profiles_df['neighbourhood_group'] == selected_group)\n",
    "                ]\n",
    "                if not selected_coords_df.empty:\n",
    "                    # Use .loc with index for pca_plot_coords to ensure alignment\n",
    "                    selected_idx = selected_coords_df.index[0]\n",
    "                    if 'pca_plot_coords' in globals() and globals().get('pca_plot_coords') is not None:\n",
    "                         plt.scatter(pca_plot_coords[selected_idx, 0], pca_plot_coords[selected_idx, 1], \n",
    "                                    s=250, edgecolor='black', facecolor='yellow', label=f\"Selected: {selected_neighbourhood}\", zorder=5)\n",
    "\n",
    "                if not recommendations.empty:\n",
    "                    rec_indices = recommendations.index\n",
    "                    if 'pca_plot_coords' in globals() and globals().get('pca_plot_coords') is not None:\n",
    "                        plt.scatter(pca_plot_coords[rec_indices, 0], \n",
    "                                    pca_plot_coords[rec_indices, 1], \n",
    "                                    s=180, edgecolor='black', facecolor='blue', marker='*', label=\"Recommended\", zorder=5)\n",
    "                        for rec_idx in rec_indices: \n",
    "                            row = final_neighbourhood_profiles_df.loc[rec_idx]\n",
    "                            plt.text(row['pca1'] + 0.05, row['pca2'] + 0.05, row['neighbourhood'], fontsize=9, zorder=5)\n",
    "\n",
    "                plt.title(f\"Neighbourhood Similarity Map (PCA Projection)\\nTarget: {selected_neighbourhood}\")\n",
    "                plt.xlabel(\"PCA Component 1\")\n",
    "                plt.ylabel(\"PCA Component 2\")\n",
    "                plt.legend(title=\"Legend\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "                plt.show()\n",
    "            else:\n",
    "                display(Markdown(\"<font color='brown'>PCA columns ('pca1', 'pca2') not found in `final_neighbourhood_profiles_df`. Plot cannot be generated.</font>\"))\n",
    "        \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            display(Markdown(f\"<font color='red'>**An error occurred in on_find_alternatives_clicked:**\\n```\\n{traceback.format_exc()}\\n```</font>\"))\n",
    "\n",
    "# Link to button (ensure this is in the same cell or run after run_button is defined)\n",
    "run_button.on_click(on_find_alternatives_clicked)\n",
    "print(\"Action function 'on_find_alternatives_clicked' (Updated for Continuous Score) defined and linked to button.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Display the Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Displaying Interactive Recommendation Interface ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 🗽 NYC Airbnb Neighbourhood Recommender"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Select a `Neighbourhood Group` and then a `Neighbourhood` you are interested in:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441a7d1a9c3946dcb8ce21787acb3092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description=\"N'hood Group:\", layout=Layout(width='auto'), options=(\"-- …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28da20e9030243ecb4ec3dab280c3c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interface is now active. Interact with the dropdowns and button above.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Displaying Interactive Recommendation Interface ---\")\n",
    "\n",
    "# Initialize neighbourhood options for the first selected group\n",
    "if group_dropdown.options and group_dropdown.options[0] != '': # Check if options exist and first is not blank\n",
    "    initial_group = group_dropdown.options[0] if group_dropdown.value == '' else group_dropdown.value\n",
    "    if initial_group: # if a valid group is selected or defaulted\n",
    "        initial_neighbourhoods = sorted(\n",
    "            final_neighbourhood_profiles_df[final_neighbourhood_profiles_df[\"neighbourhood_group\"] == initial_group][\"neighbourhood\"].unique()\n",
    "        )\n",
    "        if initial_neighbourhoods:\n",
    "             neighbourhood_dropdown.options = [''] + initial_neighbourhoods\n",
    "             # neighbourhood_dropdown.value = '' # Start with blank selection\n",
    "             neighbourhood_dropdown.disabled = False\n",
    "\n",
    "\n",
    "# Display the widgets\n",
    "display(Markdown(\"## 🗽 NYC Airbnb Neighbourhood Recommender\"))\n",
    "display(Markdown(\"Select a `Neighbourhood Group` and then a `Neighbourhood` you are interested in:\"))\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([group_dropdown, neighbourhood_dropdown]),\n",
    "    run_button\n",
    "]))\n",
    "display(output_area)\n",
    "\n",
    "print(\"\\nInterface is now active. Interact with the dropdowns and button above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
